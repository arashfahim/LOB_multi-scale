{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#New-implementation-for-GPU\" data-toc-modified-id=\"New-implementation-for-GPU-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>New implementation for GPU</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Saving-the-model\" data-toc-modified-id=\"Saving-the-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><strong>Saving the model</strong></a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Visualization</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arashfahim/LOB_multi-scale/blob/main/Impulse_3D_LOB_Forward_Non_Linear_Coarse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAeVrisqJHHm"
   },
   "source": [
    "Running cost\n",
    "\n",
    "$\\sum_{t=0}^{T-1}D_t\\xi_t+\\frac{\\kappa}{2}\\xi^{1+\\alpha}_t$\n",
    "\n",
    "Terminal cost\n",
    "\n",
    "$D_T(R_0-\\sum_{t=0}^{T-1}\\xi_t)+\\frac{\\kappa}{2}(R_0-\\sum_{t=0}^{T-1}\\xi_t)^{1+\\alpha}$\n",
    "\n",
    "For $T=2$, the total loss is\n",
    "\n",
    "$D_0\\xi_0+\\frac{\\kappa}{2}\\xi^{1+\\alpha}_0+D_1(R_0-\\xi_0)+\\frac{\\kappa}{2}(R_0-\\xi_0)^{1+\\alpha}$\n",
    "\n",
    "$D_1=\\rho(D_0+\\kappa \\xi_0^{\\alpha})$\n",
    "\n",
    "loss$=D_0\\xi_0+\\frac{\\kappa}{2}\\xi^{1+\\alpha}_0+\\rho(D_0+\\kappa \\xi_0^{\\alpha})(R_0-\\xi_0)+\\frac{\\kappa}{2}(R_0-\\xi_0)^{1+\\alpha}$\n",
    "\n",
    "$=D_0\\xi_0+\\frac{\\kappa}{2}\\xi^{1+\\alpha}_0+\\rho D_0R_0-\\rho D_0\\xi_0+\\rho R_0\\kappa \\xi_0^{\\alpha}-\\rho \\kappa \\xi_0^{1+\\alpha}+\\frac{\\kappa}{2}(R_0-\\xi_0)^{1+\\alpha}$\n",
    "\n",
    "\n",
    "\n",
    "$=\\rho D_0R_0+D_0(1-\\rho)\\xi_0 + \\frac{\\kappa}{2}(R_0^2-2(1-\\rho)\\xi_0(R_0-\\xi_0))=\\rho D_0R_0+\\frac{\\kappa}{2}R_0^2+D_0(1-\\rho)\\xi_0 - {\\kappa}(1-\\rho)\\xi_0(R_0-\\xi_0)$\n",
    "\n",
    "$(1-\\rho){\\kappa}\\xi_0(\\frac{D_0}{\\kappa} - R_0+\\xi_0)$\n",
    "\n",
    "\n",
    "$\\xi_0(\\frac{D_0}{\\kappa} - R_0+\\xi_0)$\n",
    "\n",
    "------------------------------\n",
    "\n",
    "Minimization:\n",
    "\n",
    "\n",
    "$\\xi_0^*=\\frac{R_0-\\frac{D_0}{\\kappa}}{2}=\\frac{\\kappa R_0-{D_0}{}}{2\\kappa}$\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "If $D_0=0$, $\\xi_0=\\frac{R_0}{2}$.\n",
    "\n",
    "Total cost\n",
    "\n",
    "\n",
    "$D_0\\frac{\\kappa R_0-D_0}{2\\kappa}+\\frac{\\kappa}{2}\\frac{(\\kappa R_0-D_0)^2}{4\\kappa^2}+D_1(R_0-\\frac{\\kappa R_0-D_0}{2\\kappa})+\\frac{\\kappa}{2}(R_0-\\frac{\\kappa R_0-D_0}{2\\kappa})^2$\n",
    "\n",
    "\n",
    "If $D_0=0$, $\\frac{\\kappa}{4}(1+\\rho)R_0^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:46.947625Z",
     "start_time": "2024-01-25T23:38:45.158827Z"
    },
    "id": "PqNL-4FAgMis"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "# import cvxpy as cp\n",
    "from scipy.optimize import fsolve\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:46.949799Z",
     "start_time": "2024-01-25T23:38:46.948495Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpGALyAWok9D",
    "outputId": "beaf6db7-c520-46f6-fdc8-4b99f8c685aa"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:46.951814Z",
     "start_time": "2024-01-25T23:38:46.950461Z"
    },
    "id": "lhBeFrcCouOw"
   },
   "outputs": [],
   "source": [
    "PATH = r\"/Users/fahim/Downloads/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdhilbNcbHgu"
   },
   "source": [
    "# New implementation for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:46.955139Z",
     "start_time": "2024-01-25T23:38:46.953597Z"
    },
    "id": "vFUFxSwZ4I2p"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kocykbyLUo7c"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:46.959047Z",
     "start_time": "2024-01-25T23:38:46.957267Z"
    },
    "id": "T1brENIxTbQc"
   },
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "        'M' : 1000,# number of samples\n",
    "        'T' : 1.0, # terminal time\n",
    "        'iter' : 10, #number of steps minus terminal\n",
    "        'kappa' : 1e-3, #price impact sensitivity factor\n",
    "        'rho' : 5e0, #resillience\n",
    "        'alpha' : 1.0, #price impact exponent\n",
    "        'X0' : 10000, #focus initial balance\n",
    "        'lr': 1e-2, #learning rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:46.972375Z",
     "start_time": "2024-01-25T23:38:46.959904Z"
    },
    "id": "aht2RHYvkFJo"
   },
   "outputs": [],
   "source": [
    "class opt_exe(nn.Module):#multi_step, optimal_control\n",
    "    def __init__(self,params):\n",
    "        super(opt_exe, self).__init__()\n",
    "        self.layer = torch.nn.Sequential()\n",
    "        self.layer.add_module(\"L1\",torch.nn.Linear(3, 20))\n",
    "        self.layer.add_module(\"ReLU\", torch.nn.ReLU())\n",
    "        self.layer.add_module(\"L2\",torch.nn.Linear(20,20))\n",
    "        self.layer.add_module(\"Relu\", torch.nn.ReLU())\n",
    "        # self.layer.add_module(\"L3\",torch.nn.Linear(256,128))\n",
    "        # self.layer.add_module(\"Tanh\", torch.nn.Tanh())\n",
    "        self.layer.add_module(\"L4\",torch.nn.Linear(20,1))\n",
    "        self.M = params['M']# number of samples\n",
    "        self.T= params['T'] # terminal time\n",
    "        self.iter = params['iter'] #number of steps minus terminal\n",
    "        self.Dt= torch.Tensor([self.T/self.iter]).to(device) #time step\n",
    "        self.kappa=torch.Tensor([params['kappa']]).to(device) #price impact sensitivity factor\n",
    "        self.rho=torch.exp(-params['rho']*self.Dt).to(device) #resillience<1\n",
    "        self.alpha= params['alpha'] #price impact exponent\n",
    "        self.X0=params['X0']\n",
    "        self.D = torch.zeros([self.M,1]).to(device)\n",
    "        self.R= torch.FloatTensor(self.M,1).uniform_(self.X0*0.9,self.X0*1.1).to(device)\n",
    "        # self.R= torch.linspace(self.X0*0.9,self.X0*1.1,self.M).unsqueeze(-1).to(device)#torch.FloatTensor(self.M,1).uniform_(self.X0*0.95,self.X0*1.05).to(device)\n",
    "        self.tx = torch.cat(((torch.Tensor([0.0]).repeat([self.M,1])).to(device),self.D,self.R),axis=1)\n",
    "        self.opt_path = torch.zeros([self.M,self.iter+1,3]).to(device)\n",
    "        self.opt_exe = torch.zeros([self.M,self.iter+1]).to(device)\n",
    "\n",
    "    def forward(self, tx):\n",
    "        val = self.layer(tx)\n",
    "        return val#torch.Tensor([0.5]).to(device)*tx[:,-1]#val\n",
    "\n",
    "    def unit(self,tx):\n",
    "        exe_ = self.forward(tx)# \\xi(t,X_t) optimal strategy\n",
    "        co_ = (tx[:,1]*exe_.squeeze(-1)+torch.Tensor([1/(1+self.alpha)]).to(device)*self.kappa *torch.pow(torch.abs(exe_.squeeze(-1)),1+self.alpha)) #impulse control does not have Delta t\n",
    "        up_ = torch.cat((tx[:,0].unsqueeze(-1)+self.Dt, self.rho*(tx[:,1].unsqueeze(-1)+self.kappa*torch.sign(exe_)*torch.pow(torch.abs(exe_),self.alpha)), tx[:,2].unsqueeze(-1)-exe_),axis=1) # continuous strategy needs Delta t in the amount executed\n",
    "        return exe_, co_, up_\n",
    "\n",
    "    def loss(self):\n",
    "        for i in range(self.iter):\n",
    "            if i == 0:\n",
    "                #X_0=(0,0,R_0)\n",
    "                tx = self.tx\n",
    "                exe_, co_, up_ = self.unit(tx) # \\xi(0,X_0), running cost for X_0, X_{t_1}\n",
    "                cost = co_ #record running cost\n",
    "            else:\n",
    "                # self.tx[:,i,:] = up_\n",
    "                exe_, co_, up_ = self.unit(up_) # \\xi(t_i,X_{t_i}), running cost for X_{t_i}, X_{t_{i+1}}\n",
    "                cost = cost + co_ # add the running cost\n",
    "        cost = cost + (up_[:,1]*up_[:,-1]+torch.Tensor([1/(1+self.alpha)]).to(device)*self.kappa*torch.pow(torch.abs(up_[:,-1]),1+self.alpha)).squeeze(-1)   # cost of last order is impulse and do not need self.Dt*\n",
    "        return torch.mean(cost)\n",
    "\n",
    "    def loss2(self):\n",
    "        for i in range(self.iter):\n",
    "            if i == 0:\n",
    "                #X_0=(0,0,R_0)\n",
    "                tx = self.tx\n",
    "                exe_, co_, up_ = self.unit(tx) # \\xi(0,X_0), running cost for X_0, X_{t_1}\n",
    "                # cost = co_ #record running cost\n",
    "                xi = exe_\n",
    "            else:\n",
    "                # self.tx[:,i,:] = up_\n",
    "                exe_, co_, up_ = self.unit(up_) # \\xi(t_i,X_{t_i}), running cost for X_{t_i}, X_{t_{i+1}}\n",
    "                xi = torch.concat((xi,exe_),axis=-1)\n",
    "        xi = torch.concat((xi,up_[:,-1].unsqueeze(-1)),axis=-1)\n",
    "        tau = self.rho.detach().cpu().numpy()\n",
    "        Q = np.fromfunction(lambda i, j: np.power(tau,np.abs(i-j)), (self.iter+1, self.iter+1), dtype=float)\n",
    "        Q = torch.Tensor(Q).to(device)\n",
    "        cost = torch.Tensor([0.5]).to(device)*torch.bmm(torch.matmul(xi,Q).unsqueeze(1),xi.unsqueeze(-1))*self.kappa\n",
    "        return torch.mean(cost)\n",
    "\n",
    "    def approx_loss_2(self):\n",
    "        for i in range(self.iter):\n",
    "            if i == 0:\n",
    "                self.opt_path[:,i,:] = self.tx.squeeze(-1)\n",
    "                exe_, co_, up_ = self.unit(self.tx) # \\xi(0,X_0), running cost for X_0, X_{t_1}\n",
    "                cost = co_ #record running cost\n",
    "                # sum = exe_ # record executed order\n",
    "                # print(exe_)\n",
    "                self.opt_exe[:,i] = exe_.squeeze(-1)\n",
    "            else:\n",
    "                self.opt_path[:,i,:] = up_\n",
    "                exe_, co_, up_ = self.unit(up_) # \\xi(t_i,X_{t_i}), running cost for X_{t_i}, X_{t_{i+1}}\n",
    "                cost = cost + co_ # add the running cost\n",
    "                self.opt_exe[:,i] = exe_.squeeze(-1)\n",
    "        # last step\n",
    "        self.opt_path[:,self.iter,:] = up_\n",
    "        # print(exe_)\n",
    "        remain = up_[:,-1] # remaining balance carried to the last order\n",
    "        self.opt_exe[:,self.iter] = remain\n",
    "        cost = cost + (up_[:,1]*remain+torch.Tensor([1/(1+self.alpha)]).to(device)*self.kappa *torch.pow(torch.abs(remain),1+self.alpha))   # cost of last order is impulse and do not need self.Dt*\n",
    "        return torch.mean(cost)#torch.cat((tx[:,-1].unsqueeze(-1),cost.unsqueeze(-1)),axis=1)\n",
    "\n",
    "\n",
    "    def optimal_path(self,tx):\n",
    "        M = tx.shape[0]\n",
    "        opt_path = torch.zeros([M,self.iter+1,3]).to(device)\n",
    "        opt_exe = torch.zeros([M,self.iter+1]).to(device)\n",
    "        for i in range(self.iter):\n",
    "            if i == 0:\n",
    "                opt_path[:,i,:] = tx.squeeze(-1)\n",
    "                exe_, co_, up_ = self.unit(tx) # \\xi(0,X_0), running cost for X_0, X_{t_1}\n",
    "                cost = co_ #record running cost\n",
    "                # sum = exe_ # record executed order\n",
    "                # print(exe_)\n",
    "                # print(i,\":\",exe_,\",\",up_[:,-1])\n",
    "                opt_exe[:,i] = exe_.squeeze(-1)\n",
    "            else:\n",
    "                opt_path[:,i,:] = up_\n",
    "                exe_, co_, up_ = self.unit(up_) # \\xi(t_i,X_{t_i}), running cost for X_{t_i}, X_{t_{i+1}}\n",
    "                cost = cost + co_ # add the running cost\n",
    "                # sum = sum + exe_  # add the executed order to total\n",
    "                # print(i,\":\",exe_,\",\",up_[:,-1])\n",
    "                opt_exe[:,i] = exe_.squeeze(-1)\n",
    "        # last step\n",
    "        opt_path[:,self.iter,:] = up_\n",
    "        # print(exe_)\n",
    "        remain = up_[:,-1] # remaining balance carried to the last order\n",
    "        # print(\"last: \",remain)\n",
    "        opt_exe[:,self.iter] = remain\n",
    "        cost = cost + (up_[:,1]*remain+torch.Tensor([1/(1+self.alpha)]).to(device)*self.kappa *torch.pow(torch.abs(remain),1+self.alpha))   # cost of last order is impulse and do not need self.Dt*\n",
    "        return opt_path, opt_exe, cost#torch.cat((tx[:,-1].unsqueeze(-1),cost.unsqueeze(-1)),axis=1)\n",
    "\n",
    "    def visualize(self,ind):\n",
    "        self.approx_loss_2()\n",
    "        self.eval_closed_form()\n",
    "        h = []\n",
    "        l = []\n",
    "        color = cm.rainbow(np.linspace(0, 1, len(ind)))\n",
    "        fig, ax = plt.subplots(len(ind),1,figsize=(len(ind)*2.5,5),dpi=300)\n",
    "        for i in range(len(ind)):\n",
    "            ax[i].bar(self.opt_path[ind[i],:,0].cpu().detach().numpy(),self.opt_exe[ind[i],:].clone().detach().cpu().numpy(),label=r\"$R_0$=\"+str(self.R[ind[i],0].detach().cpu().numpy()),color=color[i],width=0.5*p1.Dt.cpu().numpy())\n",
    "            h_, l_ = ax[i].get_legend_handles_labels()\n",
    "            h = h + h_\n",
    "            l = l + l_\n",
    "        ax[0].legend(h,l,loc='best',bbox_to_anchor=(1.0, 0.1, 0.2, 0.5));#, );\n",
    "        plt.tight_layout();\n",
    "\n",
    "    def eval_closed_form(self):\n",
    "        self.closed_form = dict()\n",
    "        # output = dict()\n",
    "        for index, X0 in enumerate(self.R):\n",
    "            cls0 = [X0/(2+(self.iter-1)*(1-self.rho))]\n",
    "            cls = [(1-self.rho)*cls0[0]]*(self.iter-1)\n",
    "            cls_ = cls0\n",
    "            cls = cls0+cls+cls_\n",
    "            v = torch.Tensor(cls).to(device)\n",
    "            # v = vt.detach().cpu().numpy()\n",
    "            tau = self.rho.detach().cpu().numpy()\n",
    "            Q = np.fromfunction(lambda i, j: np.power(tau,np.abs(i-j)), (self.iter+1, self.iter+1), dtype=float)\n",
    "            Q = torch.Tensor(Q).to(device)\n",
    "            cost = torch.Tensor([0.5]).to(device)*torch.matmul(torch.matmul(v,Q),v.reshape(self.iter+1,1))*self.kappa#impulse control does not have Delta t\n",
    "            self.closed_form[index] = [X0,v,cost]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:46.975991Z",
     "start_time": "2024-01-25T23:38:46.973391Z"
    },
    "id": "FXEqKR_kqz9Z"
   },
   "outputs": [],
   "source": [
    "p1 = opt_exe(param_dict).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:47.035644Z",
     "start_time": "2024-01-25T23:38:46.976983Z"
    },
    "id": "67iIMUWvClfI"
   },
   "outputs": [],
   "source": [
    "p1.eval_closed_form()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztv_NMbsmIUF"
   },
   "source": [
    "**path to save the outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:47.040736Z",
     "start_time": "2024-01-25T23:38:47.036409Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNv6oI5tShqa",
    "outputId": "4708a891-7fb9-4c62-86c1-7ce4c7e395db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0.0000,    0.0000, 9012.4785]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.tx[10,:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:47.043082Z",
     "start_time": "2024-01-25T23:38:47.041584Z"
    },
    "id": "isPnUk2RWoe4"
   },
   "outputs": [],
   "source": [
    "# p1(p1.tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:47.051186Z",
     "start_time": "2024-01-25T23:38:47.043745Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RzGwitizJkz",
    "outputId": "4a40adbe-13b8-437a-db51-8a1ba0b6aaab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 11, 3]), torch.Size([1000, 11]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.optimal_path(p1.tx)[0].shape,p1.optimal_path(p1.tx)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:47.058954Z",
     "start_time": "2024-01-25T23:38:47.054293Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-43YlM8EHrrk",
    "outputId": "9cad50bc-405d-4a3a-a178-d851166fa682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(111885.8047, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.approx_loss_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:47.464539Z",
     "start_time": "2024-01-25T23:38:47.059642Z"
    },
    "id": "0FTa3FUNsoa9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 15000\n",
    "optimizer1 = optim.Adam(p1.parameters(), param_dict['lr'])#,weight_decay=1e-2\n",
    "L_ = torch.Tensor([-2000.0]).to(device)\n",
    "cost = p1.loss()\n",
    "loss_epoch = dict()\n",
    "start=time.time()\n",
    "duration = 0\n",
    "epoch = 0\n",
    "relerr = -1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:38:47.468813Z",
     "start_time": "2024-01-25T23:38:47.465495Z"
    },
    "id": "6dn0QY_wltE4"
   },
   "outputs": [],
   "source": [
    "od = p1.state_dict()\n",
    "arch = '3D'\n",
    "for key, value in od.items():\n",
    "    if 'bias' in key:\n",
    "        arch = \"-\".join([arch,str(value.shape[0])])\n",
    "nom = '_impulse'\n",
    "for k,v in param_dict.items():\n",
    "    nom = nom + '_' + k + '_' + str(v)\n",
    "path = PATH + arch + nom\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "with open(path+\"/params.json\", \"w\") as outfile:\n",
    "    json_object = json.dumps(param_dict, indent=4)\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.430262Z",
     "start_time": "2024-01-25T23:38:47.469686Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKYCuJd-vVDJ",
    "outputId": "01e92143-3532-4f6b-8249-27ba49c05ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0 the cost is 111885.8046875.\n",
      "At epoch 1000 the cost is 14924.76171875.\n",
      "At epoch 2000 the cost is 14915.61328125.\n",
      "At epoch 3000 the cost is 14882.384765625.\n",
      "At epoch 4000 the cost is 14783.400390625.\n",
      "At epoch 5000 the cost is 14752.4140625.\n",
      "At epoch 6000 the cost is 14735.0654296875.\n",
      "At epoch 7000 the cost is 14703.2724609375.\n",
      "At epoch 8000 the cost is 14798.09375.\n",
      "At epoch 9000 the cost is 14572.65234375.\n",
      "At epoch 10000 the cost is 14570.4892578125.\n",
      "At epoch 11000 the cost is 14533.17578125.\n",
      "At epoch 12000 the cost is 14510.9296875.\n",
      "At epoch 13000 the cost is 14513.5859375.\n",
      "At epoch 14000 the cost is 14512.4091796875.\n",
      "At epoch 15000 the cost is 14511.931640625.\n",
      "Learning time: 55.96561098098755\n"
     ]
    }
   ],
   "source": [
    "while (torch.abs(L_-cost)/torch.abs(L_)>relerr) &  (epoch <= num_epochs):#\n",
    "    optimizer1.zero_grad()\n",
    "    cost=p1.loss()\n",
    "    cost.backward()\n",
    "    optimizer1.step()\n",
    "    #   before_lr = optimizer1.param_groups[0][\"lr\"]\n",
    "    #   scheduler1.step()\n",
    "    #   after_lr = optimizer1.param_groups[0][\"lr\"]\n",
    "    loss_epoch[epoch] = cost\n",
    "    if epoch>0:\n",
    "        L_ = loss_epoch[epoch-1]\n",
    "    if (epoch % 1000==0):\n",
    "        print(\"At epoch {} the cost is {}.\".format(epoch,cost.detach()))\n",
    "        # print(\"Epoch %d: SGD lr %.4f -> %.4f\" % (epoch, before_lr, after_lr))\n",
    "        # print(\"We are currently at cost {} versus analytic {}\".format(p1.approx_loss_2(torch.Tensor([[0.0, 0.0, 10.0]]).to(device)),p1.analytic_loss_2(torch.Tensor([[10.0]]).to(device))))\n",
    "    if  (torch.abs(L_-cost)/torch.abs(L_)<=relerr):\n",
    "        print(\"Delta Loss = {} , epoch = {}\".format(torch.abs(L_-cost)/torch.abs(L_),epoch))\n",
    "        print(\"Final cost tally {}\".format(p1.approx_loss_2(),cost))#,p1.analytic_loss_2(torch.Tensor([[10.0]]).to(device))\n",
    "    epoch += 1\n",
    "end= time.time()\n",
    "duration += end-start\n",
    "print(\"Learning time: {}\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.437879Z",
     "start_time": "2024-01-25T23:39:43.431161Z"
    },
    "id": "VNGPXPeIAUYM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14510.8633, grad_fn=<MeanBackward0>),\n",
       " tensor(14510.8633, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.loss(),p1.loss2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.443423Z",
     "start_time": "2024-01-25T23:39:43.438733Z"
    },
    "id": "4XS5VgM4AXOs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14510.8633, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.approx_loss_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.451133Z",
     "start_time": "2024-01-25T23:39:43.444228Z"
    },
    "id": "hXX-J2vXAdSj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14510.8633, grad_fn=<MeanBackward0>),\n",
       " tensor(14510.8633, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.loss(),p1.loss2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.515208Z",
     "start_time": "2024-01-25T23:39:43.452418Z"
    },
    "id": "5rjEWJLvtago"
   },
   "outputs": [],
   "source": [
    "loss_epoch_=dict()\n",
    "for k,v in loss_epoch.items():\n",
    "    loss_epoch_[k] = float(v.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.531067Z",
     "start_time": "2024-01-25T23:39:43.516475Z"
    },
    "id": "IrAUdtposg6e"
   },
   "outputs": [],
   "source": [
    "with open(path+\"/progress_ckeckpoint.json\", \"w\") as outfile:\n",
    "    json_object = json.dumps(loss_epoch_, indent=4)\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.534400Z",
     "start_time": "2024-01-25T23:39:43.532552Z"
    },
    "id": "ijBrN8yroIna"
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(optimizer1.state_dict()).to_csv(path+\"/optimal_path.csv\", index=False)\n",
    "# optimizer1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.539709Z",
     "start_time": "2024-01-25T23:39:43.535027Z"
    },
    "id": "na_itJ9rYeKG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14510.8633, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.approx_loss_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.543206Z",
     "start_time": "2024-01-25T23:39:43.540410Z"
    },
    "id": "CIA6ssHEs1MQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9321.7988, 7653.6729, 6936.6460, 6254.6030, 5572.0215, 4888.8921,\n",
       "        4205.2480, 3521.1199, 2852.3223, 2198.1089, 1552.7507],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.opt_path[50,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.546310Z",
     "start_time": "2024-01-25T23:39:43.543970Z"
    },
    "id": "n9EhnGiruCqc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9321.7988, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.opt_exe[50,:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy7IVGYwolhu"
   },
   "source": [
    "# **Saving the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.549786Z",
     "start_time": "2024-01-25T23:39:43.547013Z"
    },
    "id": "FXpMGiCnpNim"
   },
   "outputs": [],
   "source": [
    "torch.save(p1.state_dict(),path+\"/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:39:43.563298Z",
     "start_time": "2024-01-25T23:39:43.550890Z"
    },
    "id": "VICRVu-8qzJM"
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(p1.opt_path.cpu().detach().numpy()).to_csv(path+\"/optimal_path.csv\", index=False)\n",
    "pd.DataFrame(p1.opt_exe.cpu().detach().numpy()).to_csv(path+\"/optimal_exe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaRdagaPshh9"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.156Z"
    },
    "id": "_e-im2R4gyP_"
   },
   "outputs": [],
   "source": [
    "p1.visualize([0,int(p1.M/4),int(p1.M/2),int(3*p1.M/4),p1.M-1])\n",
    "plt.savefig(path+\"/plots.svg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.156Z"
    },
    "id": "WCZab7lEFpCS"
   },
   "outputs": [],
   "source": [
    "k = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.157Z"
    },
    "id": "v7uXRgqW1bdz"
   },
   "outputs": [],
   "source": [
    "p1.closed_form[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.158Z"
    },
    "id": "2kPWB2bf9w1x"
   },
   "outputs": [],
   "source": [
    "p1.optimal_path(p1.tx[k,:].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.158Z"
    },
    "id": "U6N7JQ1N6SvY"
   },
   "outputs": [],
   "source": [
    "print(\"The percentage of relative error is {}%.\".format((torch.abs(p1.optimal_path(p1.tx[k,:].unsqueeze(0))[-1]-p1.closed_form[k][-1])/p1.closed_form[k][-1]*100).detach().cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.159Z"
    },
    "id": "TLFS03N_DzNG"
   },
   "outputs": [],
   "source": [
    "p1.tx[k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.159Z"
    },
    "id": "BsdZ_8_h92qo"
   },
   "outputs": [],
   "source": [
    "p1.loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T23:38:45.160Z"
    },
    "id": "WnZ0lPYHRXRe"
   },
   "outputs": [],
   "source": [
    "p1.loss2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIeGaAN9Xr-H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
