{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PqNL-4FAgMis"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy import misc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Qt5Agg')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "#import cvxpy as cp\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MeYOz7uYgScR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100)\n"
     ]
    }
   ],
   "source": [
    "M=1000\n",
    "ite=100\n",
    "dim_n=3\n",
    "T=1\n",
    "delta = torch.tensor(T/ite)\n",
    "#delta=torch.tensor(0.01)\n",
    "sigma=0.2\n",
    "mu=0.3\n",
    "A0=0.0\n",
    "gamma=0.0\n",
    "kappa=1\n",
    "rho=5\n",
    "X0=10000\n",
    "neuron_model_psi=50\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "93xjaCyOgTS0"
   },
   "outputs": [],
   "source": [
    "# model= torch.nn.Sequential(\n",
    "#     torch.nn.Linear(dim_n, neuron_model_psi),\n",
    "# #     torch.nn.ReLU(),\n",
    "# #     torch.nn.Linear(neuron_model_psi, neuron_model_psi),\n",
    "# #     torch.nn.ReLU(),\n",
    "# #     torch.nn.Linear(neuron_model_psi, neuron_model_psi),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(neuron_model_psi, neuron_model_psi),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(neuron_model_psi,1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('model_N100_T1_K1_rho5_neo50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZU58vmPqgVX8"
   },
   "outputs": [],
   "source": [
    "t=torch.zeros([M,1])\n",
    "D=torch.zeros([M,1])\n",
    "#D=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "R=torch.FloatTensor(M,1).uniform_(X0*0.9,X0*1.1)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "x=torch.cat((t,D,R),dim=1)\n",
    "# print(x)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XGmOeYfAgnFK"
   },
   "outputs": [],
   "source": [
    "def update(x3,psi):\n",
    "  t=(x3[:,0]+delta)\n",
    "  #print(psi.squeeze(1).shape,x1[:,1].shape)\n",
    "  D = (x3[:,1]+kappa*psi)*torch.exp(-rho*delta)\n",
    "  R= x3[:,2]-psi\n",
    "  #print(R.shape)\n",
    "  up=torch.cat((t.unsqueeze(1),D.unsqueeze(1),R.unsqueeze(1)),dim=1)\n",
    "  #print('up shape=', up.shape)\n",
    "  return up\n",
    "\n",
    "def loss_func(x2,psi):\n",
    "  loss=(x2[:,1]*psi+(kappa/2.0)*torch.pow(psi,2))\n",
    "  return loss\n",
    "\n",
    "def unit(x1,model):\n",
    "    psi=model(x1).squeeze(1)\n",
    "    los=loss_func(x1,psi)\n",
    "    upd=update(x1,psi)\n",
    "    #print('unit print=',psi.shape,los.shape,upd.shape)\n",
    "    return psi,los,upd\n",
    "\n",
    "def loss_func_total(u,model):\n",
    "  loss=torch.zeros(M,ite)\n",
    "  psi=torch.zeros(M,ite)\n",
    "  for i in range(ite+1):\n",
    "    if(i!=ite):\n",
    "      psi_run,loss_run,u_run=unit(u,model)\n",
    "      #print('los func=',psi_run.shape,loss_run.shape)\n",
    "      loss[:,i]=loss_run\n",
    "      #print(loss)\n",
    "      psi[:,i]=psi_run\n",
    "      #print(psi)\n",
    "      u=u_run\n",
    "      #print(u)\n",
    "    else:\n",
    "      #print(torch.sum(psi,dim=1),R.squeeze(1))\n",
    "      psi_ter=R.squeeze(1)-torch.sum(psi,dim=1)\n",
    "      loss_ter=loss_func(u,psi_ter)\n",
    "      #print('ter',loss_ter.shape)\n",
    "  #print(torch.sum(loss,dim=1))\n",
    "  loss=torch.sum(loss,dim=1)+loss_ter\n",
    "  #print(loss.shape)\n",
    "  return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC2vdJPG00zc"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8C7LgFjgrSj",
    "outputId": "9697a2e1-ed0e-462a-d770-8465d959522b"
   },
   "outputs": [],
   "source": [
    "# start=time.time()\n",
    "# lr1 = 8e-3\n",
    "# epoch=0\n",
    "# num_epochs=10000\n",
    "# loss_epoch=[]\n",
    "# L_=torch.tensor([-1000])\n",
    "# optimizer = optim.Adam(model.parameters(), lr1)\n",
    "# cost=torch.tensor([100000])\n",
    "# err=1e-20\n",
    "# #print(psi.shape)\n",
    "# while (torch.abs(L_-cost)/torch.abs(L_)>err) &  (epoch <= num_epochs):\n",
    "#   optimizer.zero_grad()\n",
    "#   cost=loss_func_total(x,model)\n",
    "#   cost.backward()\n",
    "#   optimizer.step()\n",
    "#   loss_epoch.append(cost)\n",
    "#   if epoch>0:\n",
    "#     L_ = loss_epoch[epoch-1]\n",
    "#   #print(cost,L_.item())\n",
    "#   if (epoch % 100==0):\n",
    "#     print(\"At epoch {} the mean cost is {}.\".format(epoch,cost.detach()))\n",
    "#   if (torch.abs(L_-cost)/torch.abs(L_)<=err):\n",
    "#     print(\"Delta Loss = {} , epoch = {}\".format(torch.abs(L_-cost)/torch.abs(L_),epoch))\n",
    "#   epoch=epoch+1\n",
    "\n",
    "# end=time.time()\n",
    "# print('time elapsed=',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=time.time()\n",
    "# lr1 = 8e-3\n",
    "# max_epoch = 12000\n",
    "# optimizer = optim.Adam(model.parameters(), lr1)\n",
    "# cost_ar=[]\n",
    "# #print(psi.shape)\n",
    "# for epoch in range(max_epoch):\n",
    "#   optimizer.zero_grad()\n",
    "#   cost=loss_func_total(x,model)\n",
    "#   cost.backward()\n",
    "#   optimizer.step()\n",
    "#   cost_ar.append(cost)\n",
    "#   #print(loss.item())\n",
    "#   if (epoch % 100==0):\n",
    "#     print(\"At epoch {} the mean cost is {}.\".format(epoch,cost.detach()))\n",
    "# end=time.time()\n",
    "# total_time=end-start\n",
    "# print('time elapsed=',total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #time step vs training time plot\n",
    "# x=np.array([10,30,50,100]) #time steps\n",
    "# y=np.array([119,440,677,1356])#training times\n",
    "# plt.plot(x,y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wT4ALers1F8f"
   },
   "source": [
    "Solution by using cvxpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nmIbc2Wd1E2B"
   },
   "outputs": [],
   "source": [
    "def numeric_soln(X,n):\n",
    "    delt=T/n\n",
    "    alpa=math.exp(-delt*rho)\n",
    "    c=np.ones(n)\n",
    "    x=cp.Variable(n)\n",
    "    #objective=cp.Minimize(determinstic_main(x))\n",
    "    A=[[0 for i in range(n)] for j in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            A[i][j]=1-kappa+kappa*pow(alpa,abs(i-j))\n",
    "    constraints=[0<=x,sum(x)==X]\n",
    "\n",
    "    objective=cp.Minimize(1/2*cp.quad_form(x,A))\n",
    "    prob=cp.Problem(objective,constraints)\n",
    "    #print(\"prob is DCP:\", prob.is_dcp())\n",
    "    #print(\"curvature of objective:\",cp.sum(pow(x,2)).curvature)\n",
    "    #assert prob.is_dqcp()\n",
    "    cost=prob.solve()\n",
    "    #print(\"Optimal value\", prob.solve())\n",
    "    #print(\"Optimal value\", prob.solve(qcp=True))\n",
    "    #print(\"Optimal soln\")\n",
    "    soln=x.value\n",
    "    #print(soln) # A numpy ndarray\n",
    "    return soln,cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSJLhYZ-yDGS"
   },
   "source": [
    "Colsed form soln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6rs3tK1-yI_w"
   },
   "outputs": [],
   "source": [
    "def closed_form(X):\n",
    "  alpa=np.exp(-rho*T/ite)\n",
    "  p=np.zeros(ite+1)\n",
    "  p[0]=X/((ite-1)*(1-alpa)+2)\n",
    "  p[ite]=X/((ite-1)*(1-alpa)+2)\n",
    "  for j in range(1,ite):\n",
    "    p[j]=p[0]*(1-alpa)\n",
    "  return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6SwQUFvkmPl"
   },
   "source": [
    "**Calculating cost** predicted and closed cost both have the same function. I wrote it twice because of two different data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LdgOnrDvkowO"
   },
   "outputs": [],
   "source": [
    "def cost(y):\n",
    "  cost1=0.0\n",
    "  D1=0.0\n",
    "  for i in range(ite+1):\n",
    "    cost1+=D1*y[i]+(kappa/2.0)*np.power(y[i],2)\n",
    "    D1=(D1+kappa*y[i])*np.exp(-rho*T/ite)\n",
    "  return cost1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=torch.load('model_N100_T1_K1_rho5_neo50.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83IFXBNYwiIc"
   },
   "source": [
    "**Testing ** We have compared the closed form solution from Obhizaeva and Wang, our predicted solution and the solution from python convex optimization package cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVvNy5hi4vc2",
    "outputId": "e3a7a6a0-5193-4a6f-9f12-8c917599c3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of total order= 9500.0\n",
      "closed form soln= [1391.27134457   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      "   67.85310415   67.85310415   67.85310415   67.85310415   67.85310415\n",
      " 1391.27134457] sum of all execution= 9500.0\n",
      "Closed form cost= 12894775.528668163 \n",
      "\n",
      "predicted soln= tensor([1346.8529,   83.0479,   78.4997,   74.7396,   71.6170,   69.0101,\n",
      "          68.0457,   68.0327,   68.0185,   68.0031,   67.9865,   67.9687,\n",
      "          67.9497,   67.9295,   67.9081,   67.8981,   67.8999,   67.9017,\n",
      "          67.9033,   67.9050,   67.9065,   67.9080,   67.9094,   67.9108,\n",
      "          67.9121,   67.9134,   67.9146,   67.9157,   67.9141,   67.9119,\n",
      "          67.9095,   67.9068,   67.9040,   67.8960,   67.8848,   67.8731,\n",
      "          67.8608,   67.8479,   67.8345,   67.8206,   67.8061,   67.7910,\n",
      "          67.7755,   67.7593,   67.7426,   67.7254,   67.7076,   67.6893,\n",
      "          67.6705,   67.6511,   67.6312,   67.6108,   67.5898,   67.5683,\n",
      "          67.5463,   67.5237,   67.5007,   67.4771,   67.4529,   67.4283,\n",
      "          67.4031,   67.3774,   67.3512,   67.2610,   66.9599,   66.9782,\n",
      "          66.9990,   67.0224,   67.0484,   67.0770,   67.1083,   67.1422,\n",
      "          67.1788,   67.2179,   67.2598,   67.3043,   67.3515,   67.4014,\n",
      "          67.4540,   67.5093,   67.5673,   67.6280,   67.6914,   67.7576,\n",
      "          67.8266,   67.8983,   67.9727,   68.0500,   68.1300,   68.1169,\n",
      "          67.8602,   67.6816,   67.4952,   67.3008,   65.8953,   64.2795,\n",
      "          62.4342,   59.4313,   55.8617,   51.9328, 1461.1631]) sum of all execution= tensor(9499.9990)\n",
      "predicted cost= 12895506.192743879 \n",
      "\n",
      "Percent Error in cost= 0.005666357464626094 %\n",
      "\n",
      "size of total order= 9611.111\n",
      "closed form soln= [1407.54355582   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      "   68.64670926   68.64670926   68.64670926   68.64670926   68.64670926\n",
      " 1407.54355582] sum of all execution= 9611.111328124998\n",
      "Closed form cost= 13198172.231647493 \n",
      "\n",
      "predicted soln= tensor([1362.4552,   84.0044,   79.4040,   75.6008,   72.4423,   69.8055,\n",
      "          68.8122,   68.7981,   68.7828,   68.7663,   68.7486,   68.7296,\n",
      "          68.7094,   68.6880,   68.6654,   68.6537,   68.6545,   68.6552,\n",
      "          68.6559,   68.6565,   68.6571,   68.6576,   68.6580,   68.6584,\n",
      "          68.6587,   68.6589,   68.6591,   68.6592,   68.6565,   68.6533,\n",
      "          68.6498,   68.6461,   68.6422,   68.6337,   68.6214,   68.6085,\n",
      "          68.5951,   68.5812,   68.5666,   68.5516,   68.5359,   68.5197,\n",
      "          68.5030,   68.4857,   68.4679,   68.4495,   68.4306,   68.4111,\n",
      "          68.3911,   68.3706,   68.3495,   68.3279,   68.3057,   68.2830,\n",
      "          68.2598,   68.2360,   68.2117,   68.1869,   68.1616,   68.1357,\n",
      "          68.1094,   68.0825,   68.0550,   68.0063,   67.6662,   67.6840,\n",
      "          67.7045,   67.7276,   67.7533,   67.7817,   67.8127,   67.8464,\n",
      "          67.8828,   67.9218,   67.9636,   68.0081,   68.0552,   68.1051,\n",
      "          68.1577,   68.2130,   68.2711,   68.3319,   68.3955,   68.4619,\n",
      "          68.5311,   68.6030,   68.6778,   68.7553,   68.8357,   68.8609,\n",
      "          68.5904,   68.4106,   68.2228,   68.0270,   66.7046,   65.0694,\n",
      "          63.3293,   60.4505,   56.8020,   52.8956, 1482.9634]) sum of all execution= tensor(9611.1113)\n",
      "predicted cost= 13199095.149460535 \n",
      "\n",
      "Percent Error in cost= 0.006992769883917277 %\n",
      "\n",
      "size of total order= 9722.223\n",
      "closed form soln= [1423.81576707   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      "   69.44031436   69.44031436   69.44031436   69.44031436   69.44031436\n",
      " 1423.81576707] sum of all execution= 9722.22265625\n",
      "Closed form cost= 13505096.810116448 \n",
      "\n",
      "predicted soln= tensor([1378.0580,   84.9608,   80.3083,   76.4620,   73.2677,   70.6010,\n",
      "          69.5787,   69.5635,   69.5471,   69.5294,   69.5105,   69.4904,\n",
      "          69.4691,   69.4465,   69.4227,   69.4092,   69.4090,   69.4088,\n",
      "          69.4084,   69.4081,   69.4076,   69.4071,   69.4065,   69.4059,\n",
      "          69.4052,   69.4045,   69.4037,   69.4028,   69.3989,   69.3946,\n",
      "          69.3901,   69.3854,   69.3805,   69.3713,   69.3579,   69.3440,\n",
      "          69.3295,   69.3144,   69.2987,   69.2825,   69.2658,   69.2484,\n",
      "          69.2306,   69.2121,   69.1932,   69.1736,   69.1535,   69.1329,\n",
      "          69.1117,   69.0900,   69.0678,   69.0450,   69.0216,   68.9977,\n",
      "          68.9733,   68.9484,   68.9229,   68.8968,   68.8703,   68.8432,\n",
      "          68.8156,   68.7875,   68.7588,   68.7297,   68.3713,   68.3888,\n",
      "          68.4089,   68.4316,   68.4571,   68.4852,   68.5160,   68.5495,\n",
      "          68.5857,   68.6246,   68.6662,   68.7106,   68.7577,   68.8076,\n",
      "          68.8602,   68.9156,   68.9737,   69.0347,   69.0984,   69.1650,\n",
      "          69.2343,   69.3065,   69.3816,   69.4594,   69.5402,   69.6042,\n",
      "          69.3285,   69.1391,   68.9500,   68.7527,   67.5148,   65.8601,\n",
      "          64.2261,   61.4663,   57.7457,   53.8628, 1504.8008]) sum of all execution= tensor(9722.2227)\n",
      "predicted cost= 13506251.360639218 \n",
      "\n",
      "Percent Error in cost= 0.00854899849296806 %\n",
      "\n",
      "size of total order= 9833.333\n",
      "closed form soln= [1440.0878353   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      "   70.2339125   70.2339125   70.2339125   70.2339125   70.2339125\n",
      " 1440.0878353] sum of all execution= 9833.3330078125\n",
      "Closed form cost= 13815546.519991107 \n",
      "\n",
      "predicted soln= tensor([1393.6599,   85.9172,   81.2126,   77.3231,   74.0931,   71.3964,\n",
      "          70.3452,   70.3289,   70.3113,   70.2926,   70.2725,   70.2512,\n",
      "          70.2287,   70.2050,   70.1800,   70.1647,   70.1635,   70.1623,\n",
      "          70.1610,   70.1596,   70.1581,   70.1566,   70.1551,   70.1534,\n",
      "          70.1517,   70.1500,   70.1482,   70.1463,   70.1413,   70.1360,\n",
      "          70.1304,   70.1246,   70.1187,   70.1089,   70.0944,   70.0794,\n",
      "          70.0637,   70.0476,   70.0308,   70.0135,   69.9956,   69.9771,\n",
      "          69.9581,   69.9385,   69.9184,   69.8977,   69.8765,   69.8547,\n",
      "          69.8323,   69.8095,   69.7860,   69.7620,   69.7375,   69.7124,\n",
      "          69.6868,   69.6607,   69.6340,   69.6067,   69.5790,   69.5507,\n",
      "          69.5219,   69.4925,   69.4626,   69.4322,   69.0754,   69.0925,\n",
      "          69.1122,   69.1346,   69.1597,   69.1876,   69.2182,   69.2514,\n",
      "          69.2875,   69.3263,   69.3678,   69.4121,   69.4591,   69.5090,\n",
      "          69.5616,   69.6170,   69.6753,   69.7363,   69.8002,   69.8669,\n",
      "          69.9365,   70.0089,   70.0842,   70.1624,   70.2434,   70.3274,\n",
      "          70.0685,   69.8661,   69.6756,   69.4770,   68.3264,   66.6523,\n",
      "          65.0060,   62.4051,   58.7152,   54.8645, 1526.8418]) sum of all execution= tensor(9833.3330)\n",
      "predicted cost= 13816977.995866321 \n",
      "\n",
      "Percent Error in cost= 0.010361340922289216 %\n",
      "\n",
      "size of total order= 9944.444\n",
      "closed form soln= [1456.36004655   71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      "   71.0275176    71.0275176    71.0275176    71.0275176    71.0275176\n",
      " 1456.36004655] sum of all execution= 9944.444335937496\n",
      "Closed form cost= 14129526.818432625 \n",
      "\n",
      "predicted soln= tensor([1409.2626,   86.8737,   82.1169,   78.1843,   74.9184,   72.1918,\n",
      "          71.1117,   71.0943,   71.0756,   71.0557,   71.0345,   71.0121,\n",
      "          70.9884,   70.9635,   70.9373,   70.9203,   70.9181,   70.9158,\n",
      "          70.9135,   70.9111,   70.9087,   70.9062,   70.9036,   70.9009,\n",
      "          70.8983,   70.8955,   70.8927,   70.8898,   70.8837,   70.8773,\n",
      "          70.8707,   70.8639,   70.8569,   70.8465,   70.8309,   70.8148,\n",
      "          70.7980,   70.7807,   70.7629,   70.7444,   70.7254,   70.7058,\n",
      "          70.6856,   70.6649,   70.6436,   70.6218,   70.5994,   70.5764,\n",
      "          70.5529,   70.5289,   70.5043,   70.4791,   70.4534,   70.4271,\n",
      "          70.4003,   70.3730,   70.3451,   70.3166,   70.2877,   70.2581,\n",
      "          70.2281,   70.1975,   70.1664,   70.1347,   69.7794,   69.7961,\n",
      "          69.8155,   69.8376,   69.8624,   69.8900,   69.9203,   69.9534,\n",
      "          69.9892,   70.0278,   70.0693,   70.1135,   70.1605,   70.2103,\n",
      "          70.2629,   70.3184,   70.3767,   70.4379,   70.5019,   70.5688,\n",
      "          70.6386,   70.7112,   70.7868,   70.8653,   70.9466,   71.0310,\n",
      "          70.8078,   70.5923,   70.4005,   70.2004,   69.1420,   67.4450,\n",
      "          65.7795,   63.3460,   59.6871,   55.8601, 1548.9102]) sum of all execution= tensor(9944.4443)\n",
      "predicted cost= 14131272.122876259 \n",
      "\n",
      "Percent Error in cost= 0.012352178994107241 %\n",
      "\n",
      "size of total order= 10055.556\n",
      "closed form soln= [1472.6322578    71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      "   71.82112271   71.82112271   71.82112271   71.82112271   71.82112271\n",
      " 1472.6322578 ] sum of all execution= 10055.555664062498\n",
      "Closed form cost= 14447034.992363706 \n",
      "\n",
      "predicted soln= tensor([1424.8650,   87.8301,   83.0213,   79.0455,   75.7438,   72.9872,\n",
      "          71.8782,   71.8597,   71.8399,   71.8188,   71.7965,   71.7729,\n",
      "          71.7480,   71.7219,   71.6946,   71.6758,   71.6726,   71.6693,\n",
      "          71.6660,   71.6626,   71.6592,   71.6557,   71.6521,   71.6485,\n",
      "          71.6448,   71.6410,   71.6372,   71.6332,   71.6260,   71.6186,\n",
      "          71.6110,   71.6031,   71.5950,   71.5841,   71.5675,   71.5502,\n",
      "          71.5323,   71.5139,   71.4949,   71.4753,   71.4552,   71.4345,\n",
      "          71.4131,   71.3913,   71.3689,   71.3459,   71.3223,   71.2982,\n",
      "          71.2735,   71.2483,   71.2225,   71.1961,   71.1692,   71.1418,\n",
      "          71.1138,   71.0852,   71.0561,   71.0265,   70.9963,   70.9656,\n",
      "          70.9343,   70.9025,   70.8701,   70.8372,   70.4835,   70.4997,\n",
      "          70.5187,   70.5405,   70.5650,   70.5923,   70.6224,   70.6552,\n",
      "          70.6909,   70.7294,   70.7707,   70.8148,   70.8618,   70.9116,\n",
      "          70.9642,   71.0197,   71.0781,   71.1394,   71.2036,   71.2706,\n",
      "          71.3406,   71.4135,   71.4893,   71.5681,   71.6498,   71.7345,\n",
      "          71.5470,   71.3185,   71.1253,   70.9239,   69.9620,   68.2376,\n",
      "          66.5530,   64.2869,   60.6590,   56.8538, 1570.9795]) sum of all execution= tensor(10055.5566)\n",
      "predicted cost= 14449135.72469641 \n",
      "\n",
      "Percent Error in cost= 0.014540923683060064 %\n",
      "\n",
      "size of total order= 10166.667\n",
      "closed form soln= [1488.90446905   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      "   72.61472782   72.61472782   72.61472782   72.61472782   72.61472782\n",
      " 1488.90446905] sum of all execution= 10166.666992187502\n",
      "Closed form cost= 14768071.041784417 \n",
      "\n",
      "predicted soln= tensor([1440.4672,   88.7866,   83.9256,   79.9068,   76.5692,   73.7827,\n",
      "          72.6447,   72.6251,   72.6042,   72.5820,   72.5585,   72.5338,\n",
      "          72.5077,   72.4805,   72.4519,   72.4313,   72.4271,   72.4229,\n",
      "          72.4186,   72.4142,   72.4097,   72.4052,   72.4007,   72.3961,\n",
      "          72.3914,   72.3866,   72.3818,   72.3767,   72.3684,   72.3600,\n",
      "          72.3513,   72.3424,   72.3333,   72.3218,   72.3040,   72.2856,\n",
      "          72.2667,   72.2471,   72.2270,   72.2063,   72.1850,   72.1632,\n",
      "          72.1407,   72.1177,   72.0942,   72.0700,   72.0453,   72.0200,\n",
      "          71.9942,   71.9678,   71.9408,   71.9132,   71.8851,   71.8565,\n",
      "          71.8273,   71.7976,   71.7673,   71.7364,   71.7050,   71.6731,\n",
      "          71.6406,   71.6075,   71.5740,   71.5398,   71.2060,   71.2044,\n",
      "          71.2230,   71.2445,   71.2687,   71.2957,   71.3256,   71.3582,\n",
      "          71.3937,   71.4321,   71.4732,   71.5173,   71.5642,   71.6140,\n",
      "          71.6667,   71.7222,   71.7807,   71.8421,   71.9064,   71.9736,\n",
      "          72.0438,   72.1169,   72.1930,   72.2721,   72.3542,   72.4392,\n",
      "          72.2869,   72.0455,   71.8510,   71.6481,   70.7808,   69.0292,\n",
      "          67.3254,   65.2246,   61.6273,   57.8432, 1593.0088]) sum of all execution= tensor(10166.6670)\n",
      "predicted cost= 14770560.492115308 \n",
      "\n",
      "Percent Error in cost= 0.01685697694605562 %\n",
      "\n",
      "size of total order= 10277.777\n",
      "closed form soln= [1505.17653728   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      "   73.40832595   73.40832595   73.40832595   73.40832595   73.40832595\n",
      " 1505.17653728] sum of all execution= 10277.77734375\n",
      "Closed form cost= 15092632.09858445 \n",
      "\n",
      "predicted soln= tensor([1456.0696,   89.7430,   84.8299,   80.7679,   77.3945,   74.5781,\n",
      "          73.4112,   73.3905,   73.3685,   73.3452,   73.3205,   73.2946,\n",
      "          73.2674,   73.2390,   73.2092,   73.1869,   73.1817,   73.1764,\n",
      "          73.1711,   73.1657,   73.1603,   73.1548,   73.1492,   73.1436,\n",
      "          73.1379,   73.1321,   73.1264,   73.1201,   73.1108,   73.1013,\n",
      "          73.0916,   73.0817,   73.0715,   73.0594,   73.0405,   73.0210,\n",
      "          73.0010,   72.9803,   72.9591,   72.9373,   72.9149,   72.8919,\n",
      "          72.8683,   72.8441,   72.8194,   72.7941,   72.7682,   72.7418,\n",
      "          72.7148,   72.6872,   72.6591,   72.6303,   72.6011,   72.5712,\n",
      "          72.5408,   72.5099,   72.4784,   72.4463,   72.4137,   72.3805,\n",
      "          72.3468,   72.3126,   72.2778,   72.2424,   71.9455,   71.9099,\n",
      "          71.9282,   71.9493,   71.9732,   72.0000,   72.0296,   72.0620,\n",
      "          72.0974,   72.1356,   72.1767,   72.2206,   72.2675,   72.3173,\n",
      "          72.3699,   72.4256,   72.4841,   72.5456,   72.6101,   72.6775,\n",
      "          72.7479,   72.8212,   72.8976,   72.9770,   73.0594,   73.1449,\n",
      "          73.0275,   72.7732,   72.5773,   72.3730,   71.5986,   69.8198,\n",
      "          68.0969,   66.1174,   62.5974,   58.8350, 1615.0420]) sum of all execution= tensor(10277.7773)\n",
      "predicted cost= 15095548.962275494 \n",
      "\n",
      "Percent Error in cost= 0.019326408223497897 %\n",
      "\n",
      "size of total order= 10388.889\n",
      "closed form soln= [1521.44874853   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      "   74.20193106   74.20193106   74.20193106   74.20193106   74.20193106\n",
      " 1521.44874853] sum of all execution= 10388.888671874996\n",
      "Closed form cost= 15420723.867977738 \n",
      "\n",
      "predicted soln= tensor([1471.6718,   90.6996,   85.7342,   81.6292,   78.2199,   75.3736,\n",
      "          74.1777,   74.1559,   74.1327,   74.1083,   74.0825,   74.0554,\n",
      "          74.0271,   73.9974,   73.9665,   73.9424,   73.9362,   73.9300,\n",
      "          73.9236,   73.9173,   73.9108,   73.9043,   73.8978,   73.8911,\n",
      "          73.8844,   73.8777,   73.8709,   73.8635,   73.8532,   73.8427,\n",
      "          73.8319,   73.8209,   73.8097,   73.7970,   73.7770,   73.7564,\n",
      "          73.7353,   73.7135,   73.6911,   73.6682,   73.6446,   73.6205,\n",
      "          73.5958,   73.5705,   73.5446,   73.5182,   73.4911,   73.4635,\n",
      "          73.4354,   73.4066,   73.3773,   73.3474,   73.3169,   73.2859,\n",
      "          73.2543,   73.2222,   73.1895,   73.1562,   73.1224,   73.0880,\n",
      "          73.0530,   73.0175,   72.9815,   72.9449,   72.6850,   72.6153,\n",
      "          72.6332,   72.6540,   72.6777,   72.7041,   72.7335,   72.7658,\n",
      "          72.8009,   72.8390,   72.8800,   72.9239,   72.9707,   73.0205,\n",
      "          73.0732,   73.1288,   73.1875,   73.2491,   73.3137,   73.3813,\n",
      "          73.4519,   73.5255,   73.6021,   73.6818,   73.7646,   73.8504,\n",
      "          73.7679,   73.5008,   73.3036,   73.0978,   72.4165,   70.6105,\n",
      "          68.8684,   66.9837,   63.5705,   59.7841, 1637.1455]) sum of all execution= tensor(10388.8877)\n",
      "predicted cost= 15424103.903045166 \n",
      "\n",
      "Percent Error in cost= 0.02191878342654714 %\n",
      "\n",
      "size of total order= 10500.0\n",
      "closed form soln= [1537.72095978   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      "   74.99553617   74.99553617   74.99553617   74.99553617   74.99553617\n",
      " 1537.72095978] sum of all execution= 10499.999999999996\n",
      "Closed form cost= 15752343.51286057 \n",
      "\n",
      "predicted soln= tensor([1487.2742,   91.6560,   86.6386,   82.4904,   79.0453,   76.1690,\n",
      "          74.9442,   74.9213,   74.8970,   74.8714,   74.8445,   74.8163,\n",
      "          74.7868,   74.7559,   74.7238,   74.6979,   74.6908,   74.6835,\n",
      "          74.6762,   74.6688,   74.6614,   74.6539,   74.6463,   74.6387,\n",
      "          74.6310,   74.6232,   74.6154,   74.6069,   74.5956,   74.5840,\n",
      "          74.5722,   74.5602,   74.5479,   74.5346,   74.5135,   74.4919,\n",
      "          74.4696,   74.4467,   74.4232,   74.3991,   74.3745,   74.3492,\n",
      "          74.3234,   74.2969,   74.2699,   74.2423,   74.2141,   74.1853,\n",
      "          74.1560,   74.1261,   74.0956,   74.0645,   74.0328,   74.0006,\n",
      "          73.9678,   73.9345,   73.9006,   73.8661,   73.8310,   73.7954,\n",
      "          73.7593,   73.7226,   73.6853,   73.6475,   73.4245,   73.3208,\n",
      "          73.3384,   73.3588,   73.3822,   73.4084,   73.4376,   73.4696,\n",
      "          73.5046,   73.5425,   73.5834,   73.6272,   73.6740,   73.7237,\n",
      "          73.7765,   73.8322,   73.8909,   73.9526,   74.0174,   74.0851,\n",
      "          74.1560,   74.2298,   74.3067,   74.3868,   74.4698,   74.5560,\n",
      "          74.5084,   74.2284,   74.0299,   73.8226,   73.2344,   71.4012,\n",
      "          69.6400,   67.8499,   64.5257,   60.6850, 1659.3115]) sum of all execution= tensor(10500.)\n",
      "predicted cost= 15756226.596851118 \n",
      "\n",
      "Percent Error in cost= 0.024650833619629792 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.modules.pooling import MaxPool1d\n",
    "M1=10\n",
    "t_test=torch.zeros([M1,1])\n",
    "D_test=torch.zeros([M1,1])\n",
    "#D_test=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "#R_test=torch.FloatTensor(M1,1).uniform_(50,100)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "R_test=torch.linspace(X0*0.95, X0*1.05, steps=M1).unsqueeze(1)\n",
    "x_test=torch.cat((t_test,D_test,R_test),dim=1)\n",
    "#print('Input=',x_test,'\\n')\n",
    "a=torch.zeros(M1,ite+1)\n",
    "#print(a.shape)\n",
    "for i in range(ite+1):\n",
    "  if(i!=ite):\n",
    "    #print(x_test)\n",
    "    soln_pred=model(x_test).squeeze(1).detach()\n",
    "    a[:,i]=soln_pred\n",
    "    x_test=update(x_test,soln_pred)\n",
    "    #print(x_test,'\\n')\n",
    "  else:\n",
    "    a[:,i]=R_test.squeeze(1)-torch.sum(a,dim=1)\n",
    "\n",
    "x1=R_test.squeeze().numpy()\n",
    "c_true=np.zeros(M1)\n",
    "c_pred=np.zeros(M1)\n",
    "c_num=np.zeros(M1)\n",
    "n_soln=np.zeros((M1,ite+1))\n",
    "t_soln=np.zeros((M1,ite+1))\n",
    "\n",
    "for i in range(M1):\n",
    "  print('size of total order=',x1[i])\n",
    "\n",
    "  t_soln[i,:]=closed_form(x1[i])\n",
    "  print('closed form soln=',t_soln[i,:],'sum of all execution=',np.sum(t_soln[i,:]))\n",
    "  true_cost=cost(t_soln[i,:])\n",
    "  c_true[i]=true_cost\n",
    "  print('Closed form cost=',true_cost,'\\n')\n",
    "\n",
    "  print('predicted soln=',a[i,:],'sum of all execution=',torch.sum(a[i,:]).detach())\n",
    "  pred_cost=cost(a[i,:].detach().numpy())\n",
    "  print('predicted cost=',pred_cost,'\\n')\n",
    "  c_pred[i]=pred_cost\n",
    "  print('Percent Error in cost=',np.abs(100*(true_cost-pred_cost)/true_cost),'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIUWsQuCMJoI"
   },
   "source": [
    "Comparing the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "v2AdyYZLMHES",
    "outputId": "b299a6b2-a7cf-42e9-a2cf-5f39556e79d7"
   },
   "outputs": [],
   "source": [
    "# print(x1.shape)\n",
    "# name='E:/Robin research/ECMF_poster/N50.eps'\n",
    "# plt.figure()\n",
    "# plt.plot(x1,c_true,color='blue',label='cost_true',marker='1')\n",
    "# plt.plot(x1,c_pred,color='red',label='cost_predicted')\n",
    "# plt.plot(x1,c_num,color='green',label='cost_numeric')\n",
    "# plt.legend()\n",
    "# plt.savefig(name,format='eps')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDVg2A6yAt57"
   },
   "source": [
    "Comparing solution for diffeternt testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vOZyCiOfA2ej",
    "outputId": "43fe60aa-e0af-41d1-ca70-b0e9e8652ed9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n"
     ]
    }
   ],
   "source": [
    "p_soln=a.numpy()\n",
    "t_step=np.linspace(0,ite,num=ite+1)\n",
    "# name='/Users/shirinprovat/Desktop/Robin_Research/LOB_Linear/N_10_Linear.eps'\n",
    "def plotting(t):\n",
    "  #print('Total order size=',x1[t],np.sum(n_soln[t]),np.sum(p_soln[t]))\n",
    "  #print(n_soln[t],p_soln[t])\n",
    "  #plt.figure(figsize=(4,3))\n",
    "  plt.bar(t_step,t_soln[t],color='blue',width=0.3,label='Closed-Form')\n",
    "  plt.bar(t_step,p_soln[t],color='red',width=0.2,label='Predicted')\n",
    "  #plt.bar(t_step,n_soln[t],color='green',width=0.1,label='numeric')\n",
    "  plt.title('Total Order size X= %i' % (x1[t]))\n",
    "  plt.xlabel('Time steps')\n",
    "  plt.ylabel('Optimal orders')\n",
    "  plt.legend()\n",
    "\n",
    "  #plt.savefig('f.eps', format='eps')\n",
    "#   if(t==0):\n",
    "#     plt.savefig(name,format='eps')      \n",
    "  plt.show()\n",
    "for i in range(0,M1,3):\n",
    "  plotting(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'model_N10_T1_K1_rho5_neo20.pth') \n",
    "#model_coarse = torch.load('model_N10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# cost_numpy_list = [tensor.detach().item() for tensor in cost_ar]\n",
    "# my_dic = {'Num_sample':M,'Time_step':ite,'T':T,'kappa':kappa,'Rho':rho,'Total_balance':X0,\n",
    "#         'Num_neoron':neuron_model_psi,'Training_time':total_time,'epoch':max_epoch,\n",
    "#           'accuracy':0.005*1/100,'Training_cost':cost_numpy_list}\n",
    "\n",
    "# file_path=  'N10_T1_rho5_linear_dic.json'\n",
    "# with open(file_path,'w') as file:\n",
    "#     json.dump(my_dic,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDxwTUz0cM7i"
   },
   "source": [
    "Comparing solution at different time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "fhTjyEOhcTDi",
    "outputId": "f7434824-b622-4684-cba5-de03d91e7a07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "/var/folders/9f/dlwft6dn7hxg65r7xqyxvk6r0000gn/T/ipykernel_22636/2983102215.py:6: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(4,3))\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n"
     ]
    }
   ],
   "source": [
    "#p_soln=a.numpy()\n",
    "t_step=np.linspace(0,ite,num=ite+1)\n",
    "X=R_test.squeeze(1).numpy()\n",
    "def plotting_time(t):\n",
    "  #print(t_soln[t],p_soln[t])\n",
    "  plt.figure(figsize=(4,3))\n",
    "  plt.plot(X,t_soln[:,0],color='blue',label='true')\n",
    "  plt.plot(X,p_soln[:,0],color='red',label='pred')\n",
    "  plt.plot(X,n_soln[:,0],color='green',label='numeric')\n",
    "  plt.title('At time= %d' % (t_step[t]))\n",
    "  plt.xlabel('Total Order size')\n",
    "  plt.ylabel('Optimal orders')\n",
    "  plt.legend()\n",
    "  plt.show\n",
    "for i in range(0,t_step.shape[0],5):\n",
    "  plotting_time(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "freyX0vxj9Gi"
   },
   "source": [
    "Absolute sum of the difference between true solution, predicted solution and true soln, numeric soln at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "qKbuJp7tkOCY",
    "outputId": "7ae3d0aa-ccd8-442d-a735-0ac3915f0093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500.0      221.41187673622665\n",
      "9611.111328124998      230.0424365977047\n",
      "9722.22265625      240.5576000704491\n",
      "9833.3330078125      252.05621073784056\n",
      "9944.444335937496      263.8710108440346\n",
      "10055.555664062498      275.9676000520761\n",
      "10166.666992187502      288.0836555436982\n",
      "10277.77734375      300.2795533844354\n",
      "10388.888671874996      312.68681859704753\n",
      "10499.999999999996      325.2235683815835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9f/dlwft6dn7hxg65r7xqyxvk6r0000gn/T/ipykernel_22636/1059018647.py:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(4,2))\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x326c1e5d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_error=np.zeros(M1)\n",
    "sq_error_num=np.zeros(M1)\n",
    "\n",
    "for i in range(M1):\n",
    "  sq_error[i]=np.sum(np.abs(t_soln[i]-p_soln[i]))\n",
    "  sq_error_num[i]=np.sum(np.abs(t_soln[i]-n_soln[i]))\n",
    "  print(np.sum(t_soln[i]),'    ',sq_error[i])\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(X,sq_error,color='blue',label='pred')\n",
    "#plt.plot(X,sq_error_num,color='green',label='numeric')\n",
    "plt.title('Error with sample size= %d' % (M1))\n",
    "plt.xlabel('Total Order size')\n",
    "plt.ylabel('Sum of execution error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQzIyZHqqm5t"
   },
   "source": [
    "Additional rough test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "D-HLzw6CgLjT"
   },
   "outputs": [],
   "source": [
    "# from torch.nn.modules.pooling import MaxPool1d\n",
    "# M1=100\n",
    "# t_test=torch.zeros([M1,1])\n",
    "# D_test=torch.zeros([M1,1])\n",
    "# #D_test=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "# R_test=torch.linspace(50,100,100).unsqueeze(1)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "# x_test=torch.cat((t_test,D_test,R_test),dim=1)\n",
    "# #print('Input=',x_test,'\\n')\n",
    "# soln=[]\n",
    "# x_update = x_test\n",
    "# #print(x_update)\n",
    "# for i in range(ite+1):\n",
    "#     #print(x_update)\n",
    "#     soln_pred=model(x_update)\n",
    "#     #print(soln_pred)\n",
    "#     x_udpate=update(x_update,soln_pred.squeeze(1))\n",
    "#     #print(x_update)\n",
    "#     soln.append(soln_pred)\n",
    "# strategy = torch.cat(soln,dim=1)\n",
    "# print(strategy)\n",
    "# # print('predicted soln=',strategy,'sum of all execution=',torch.sum(strategy,dim=1),'\\n')\n",
    "# a=[]\n",
    "# b=[]\n",
    "# c=[]\n",
    "# for x in R_test:\n",
    "#     a.append(x.numpy()[0])\n",
    "#     y=closed_form(x.numpy()[0],ite+1)\n",
    "#     #print(y)\n",
    "#     b.append(y[0][0])\n",
    "#     c.append(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model= torch.load('model_N10.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.modules.pooling #model= torch.load('model_N10.pth')import MaxPool1d\n",
    "# M1=20\n",
    "# t_test=torch.zeros([M1,1])\n",
    "# D_test=torch.zeros([M1,1])\n",
    "# #D_test=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "# #R_test=torch.FloatTensor(M1,1).uniform_(50,100)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "# R_test=torch.linspace(X0*0.95, X0*1.05, steps=M1).unsqueeze(1)\n",
    "# x_test=torch.cat((t_test,D_test,R_test),dim=1)\n",
    "# #print('Input=',x_test,'\\n')\n",
    "# a=torch.zeros(M1,ite+1)\n",
    "# #print(a.shape)\n",
    "# for i in range(ite+1):\n",
    "#   if(i!=ite):\n",
    "#     #print(x_test)\n",
    "#     soln_pred=model(x_test).squeeze(1).detach()\n",
    "#     a[:,i]=soln_pred\n",
    "#     x_test=update(x_test,soln_pred)\n",
    "#     #print(x_test,'\\n')\n",
    "#   else:\n",
    "#     a[:,i]=R_test.squeeze(1)-torch.sum(a,dim=1)\n",
    "\n",
    "# x1=R_test.squeeze().numpy()\n",
    "# c_true=np.zeros(M1)\n",
    "# c_pred=np.zeros(M1)\n",
    "# c_num=np.zeros(M1)\n",
    "# n_soln=np.zeros((M1,ite+1))\n",
    "# t_soln=np.zeros((M1,ite+1))\n",
    "\n",
    "# for i in range(M1):\n",
    "#   print('size of total order=',x1[i])\n",
    "\n",
    "#   t_soln[i,:]=closed_form(x1[i])\n",
    "#   print('closed form soln=',t_soln[i,:],'sum of all execution=',np.sum(t_soln[i,:]))\n",
    "#   true_cost=cost(t_soln[i,:])\n",
    "#   c_true[i]=true_cost\n",
    "#   print('Closed form cost=',true_cost,'\\n')\n",
    "\n",
    "#   print('predicted soln=',a[i,:],'sum of all execution=',torch.sum(a[i,:]).detach())\n",
    "#   pred_cost=cost(a[i,:].detach().numpy())\n",
    "#   print('predicted cost=',pred_cost,'\\n')\n",
    "#   c_pred[i]=pred_cost\n",
    "#   print('Percent Error in cost=',np.abs(100*(true_cost-pred_cost)/true_cost),'%\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
