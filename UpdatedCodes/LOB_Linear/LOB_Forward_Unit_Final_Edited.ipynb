{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "PqNL-4FAgMis"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy import misc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Qt5Agg')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "#import cvxpy as cp\n",
    "from scipy.optimize import fsolve\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MeYOz7uYgScR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100)\n"
     ]
    }
   ],
   "source": [
    "M=1000\n",
    "ite=100\n",
    "dim_n=3\n",
    "T=1\n",
    "delta = torch.tensor(T/ite)\n",
    "#delta=torch.tensor(0.01)\n",
    "sigma=0.2\n",
    "mu=0.3\n",
    "A0=0.0\n",
    "gamma=0.0\n",
    "kappa=1\n",
    "rho=5\n",
    "X0=10000\n",
    "neuron_model_psi=50\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "93xjaCyOgTS0"
   },
   "outputs": [],
   "source": [
    "model= torch.nn.Sequential(\n",
    "    torch.nn.Linear(dim_n, neuron_model_psi),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(neuron_model_psi, neuron_model_psi),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(neuron_model_psi, neuron_model_psi),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(neuron_model_psi, neuron_model_psi),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(neuron_model_psi,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=torch.load('model_N100_T1_K1_rho5_neo50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ZU58vmPqgVX8"
   },
   "outputs": [],
   "source": [
    "t=torch.zeros([M,1])\n",
    "D=torch.zeros([M,1])\n",
    "#D=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "R=torch.FloatTensor(M,1).uniform_(X0*0.9,X0*1.1)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "x=torch.cat((t,D,R),dim=1)\n",
    "# print(x)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XGmOeYfAgnFK"
   },
   "outputs": [],
   "source": [
    "def update(x3,psi):\n",
    "  t=(x3[:,0]+delta)\n",
    "  #print(psi.squeeze(1).shape,x1[:,1].shape)\n",
    "  D = (x3[:,1]+kappa*psi)*torch.exp(-rho*delta)\n",
    "  R= x3[:,2]-psi\n",
    "  #print(R.shape)\n",
    "  up=torch.cat((t.unsqueeze(1),D.unsqueeze(1),R.unsqueeze(1)),dim=1)\n",
    "  #print('up shape=', up.shape)\n",
    "  return up\n",
    "\n",
    "def loss_func(x2,psi):\n",
    "  loss=(x2[:,1]*psi+(kappa/2.0)*torch.pow(psi,2))\n",
    "  return loss\n",
    "\n",
    "def unit(x1,model):\n",
    "    psi=model(x1).squeeze(1)\n",
    "    los=loss_func(x1,psi)\n",
    "    upd=update(x1,psi)\n",
    "    #print('unit print=',psi.shape,los.shape,upd.shape)\n",
    "    return psi,los,upd\n",
    "\n",
    "def loss_func_total(u,model):\n",
    "  loss=torch.zeros(M,ite)\n",
    "  psi=torch.zeros(M,ite)\n",
    "  for i in range(ite+1):\n",
    "    if(i!=ite):\n",
    "      psi_run,loss_run,u_run=unit(u,model)\n",
    "      #print('los func=',psi_run.shape,loss_run.shape)\n",
    "      loss[:,i]=loss_run\n",
    "      #print(loss)\n",
    "      psi[:,i]=psi_run\n",
    "      #print(psi)\n",
    "      u=u_run\n",
    "      #print(u)\n",
    "    else:\n",
    "      #print(torch.sum(psi,dim=1),R.squeeze(1))\n",
    "      psi_ter=R.squeeze(1)-torch.sum(psi,dim=1)\n",
    "      loss_ter=loss_func(u,psi_ter)\n",
    "      #print('ter',loss_ter.shape)\n",
    "  #print(torch.sum(loss,dim=1))\n",
    "  loss=torch.sum(loss,dim=1)+loss_ter\n",
    "  #print(loss.shape)\n",
    "  return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC2vdJPG00zc"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8C7LgFjgrSj",
    "outputId": "9697a2e1-ed0e-462a-d770-8465d959522b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0 the mean cost is 81825997.37675345.  Eproch training time = 1.58E+03 ms\n",
      "At epoch 199 the mean cost is 15297102.162401345.  Eproch training time = 1.01E+03 ms\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "lr1 = 8e-3\n",
    "epoch=0\n",
    "num_epochs=1000\n",
    "loss_epoch=[]\n",
    "L_=torch.tensor([-1000])\n",
    "optimizer = optim.Adam(model.parameters(), lr1)\n",
    "cost=torch.tensor([100000])\n",
    "err=1e-10\n",
    "#print(psi.shape)\n",
    "while (torch.abs(L_-cost)/torch.abs(L_)>err) &  (epoch <= num_epochs):\n",
    "  t0 = time.time()\n",
    "  optimizer.zero_grad()\n",
    "  cost=loss_func_total(x,model)\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "  loss_epoch.append(cost)\n",
    "  if epoch>0:\n",
    "    L_ = loss_epoch[epoch-1]\n",
    "  #print(cost,L_.item())\n",
    "  if (epoch % int(num_epochs/5)== int(num_epochs/5)-1) | (epoch == 0):\n",
    "    print(\"At epoch {} the mean cost is {}.  Eproch training time = {:.2E} ms\".format(epoch,cost.detach(),1000*(time.time()-t0)))\n",
    "  if (torch.abs(L_-cost)/torch.abs(L_)<=err):\n",
    "    print(\"Delta Loss = {} , epoch = {}.\".format(torch.abs(L_-cost)/torch.abs(L_),epoch))\n",
    "  \n",
    "  epoch=epoch+1\n",
    "\n",
    "end=time.time()\n",
    "print('time elapsed=',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_N100_Arash.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=time.time()\n",
    "# lr1 = 8e-3\n",
    "# max_epoch = 12000\n",
    "# optimizer = optim.Adam(model.parameters(), lr1)\n",
    "# cost_ar=[]\n",
    "# #print(psi.shape)\n",
    "# for epoch in range(max_epoch):\n",
    "#   optimizer.zero_grad()\n",
    "#   cost=loss_func_total(x,model)\n",
    "#   cost.backward()\n",
    "#   optimizer.step()\n",
    "#   cost_ar.append(cost)\n",
    "#   #print(loss.item())\n",
    "#   if (epoch % 100==0):\n",
    "#     print(\"At epoch {} the mean cost is {}.\".format(epoch,cost.detach()))\n",
    "# end=time.time()\n",
    "# total_time=end-start\n",
    "# print('time elapsed=',total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #time step vs training time plot\n",
    "# x=np.array([10,30,50,100]) #time steps\n",
    "# y=np.array([119,440,677,1356])#training times\n",
    "# plt.plot(x,y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wT4ALers1F8f"
   },
   "source": [
    "Solution by using cvxpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmIbc2Wd1E2B"
   },
   "outputs": [],
   "source": [
    "# def numeric_soln(X,n):\n",
    "#     delt=T/n\n",
    "#     alpa=math.exp(-delt*rho)\n",
    "#     c=np.ones(n)\n",
    "#     x=cp.Variable(n)\n",
    "#     #objective=cp.Minimize(determinstic_main(x))\n",
    "#     A=[[0 for i in range(n)] for j in range(n)]\n",
    "#     for i in range(n):\n",
    "#         for j in range(n):\n",
    "#             A[i][j]=1-kappa+kappa*pow(alpa,abs(i-j))\n",
    "#     constraints=[0<=x,sum(x)==X]\n",
    "\n",
    "#     objective=cp.Minimize(1/2*cp.quad_form(x,A))\n",
    "#     prob=cp.Problem(objective,constraints)\n",
    "#     #print(\"prob is DCP:\", prob.is_dcp())\n",
    "#     #print(\"curvature of objective:\",cp.sum(pow(x,2)).curvature)\n",
    "#     #assert prob.is_dqcp()\n",
    "#     cost=prob.solve()\n",
    "#     #print(\"Optimal value\", prob.solve())\n",
    "#     #print(\"Optimal value\", prob.solve(qcp=True))\n",
    "#     #print(\"Optimal soln\")\n",
    "#     soln=x.value\n",
    "#     #print(soln) # A numpy ndarray\n",
    "#     return soln,cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSJLhYZ-yDGS"
   },
   "source": [
    "Colsed form soln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rs3tK1-yI_w"
   },
   "outputs": [],
   "source": [
    "def closed_form(X):\n",
    "  alpa=np.exp(-rho*T/ite)\n",
    "  p=np.zeros(ite+1)\n",
    "  p[0]=X/((ite-1)*(1-alpa)+2)\n",
    "  p[ite]=X/((ite-1)*(1-alpa)+2)\n",
    "  for j in range(1,ite):\n",
    "    p[j]=p[0]*(1-alpa)\n",
    "  return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6SwQUFvkmPl"
   },
   "source": [
    "**Calculating cost** predicted and closed cost both have the same function. I wrote it twice because of two different data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdgOnrDvkowO"
   },
   "outputs": [],
   "source": [
    "def cost(y):\n",
    "  cost1=0.0\n",
    "  D1=0.0\n",
    "  for i in range(ite+1):\n",
    "    cost1+=D1*y[i]+(kappa/2.0)*np.power(y[i],2)\n",
    "    D1=(D1+kappa*y[i])*np.exp(-rho*T/ite)\n",
    "  return cost1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('model_N100_T1_K1_rho5_neo50.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83IFXBNYwiIc"
   },
   "source": [
    "**Testing ** We have compared the closed form solution from Obhizaeva and Wang, our predicted solution and the solution from python convex optimization package cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVvNy5hi4vc2",
    "outputId": "e3a7a6a0-5193-4a6f-9f12-8c917599c3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(i\u001b[38;5;241m!=\u001b[39mite):\n\u001b[1;32m     14\u001b[0m   \u001b[38;5;28mprint\u001b[39m(x_test\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m---> 15\u001b[0m   soln_pred\u001b[38;5;241m=\u001b[39mmodel(x_test)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     16\u001b[0m   a[:,i]\u001b[38;5;241m=\u001b[39msoln_pred\n\u001b[1;32m     17\u001b[0m   x_test\u001b[38;5;241m=\u001b[39mupdate(x_test,soln_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "from torch.nn.modules.pooling import MaxPool1d\n",
    "M1=10\n",
    "t_test=torch.zeros([M1,1])\n",
    "D_test=torch.zeros([M1,1])\n",
    "#D_test=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "#R_test=torch.FloatTensor(M1,1).uniform_(50,100)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "R_test=torch.linspace(X0*0.95, X0*1.05, steps=M1).unsqueeze(1)\n",
    "x_test=torch.cat((t_test,D_test,R_test),dim=1)\n",
    "#print('Input=',x_test,'\\n')\n",
    "a=torch.zeros(M1,ite+1)\n",
    "#print(a.shape)\n",
    "for i in range(ite+1):\n",
    "  if(i!=ite):\n",
    "    print(x_test.dtype)\n",
    "    soln_pred=model(x_test).squeeze(1).detach()\n",
    "    a[:,i]=soln_pred\n",
    "    x_test=update(x_test,soln_pred)\n",
    "    #print(x_test,'\\n')\n",
    "  else:\n",
    "    a[:,i]=R_test.squeeze(1)-torch.sum(a,dim=1)\n",
    "\n",
    "x1=R_test.squeeze().numpy()\n",
    "c_true=np.zeros(M1)\n",
    "c_pred=np.zeros(M1)\n",
    "c_num=np.zeros(M1)\n",
    "n_soln=np.zeros((M1,ite+1))\n",
    "t_soln=np.zeros((M1,ite+1))\n",
    "\n",
    "for i in range(M1):\n",
    "  print('size of total order=',x1[i])\n",
    "\n",
    "  t_soln[i,:]=closed_form(x1[i])\n",
    "  print('closed form soln=',t_soln[i,:],'sum of all execution=',np.sum(t_soln[i,:]))\n",
    "  true_cost=cost(t_soln[i,:])\n",
    "  c_true[i]=true_cost\n",
    "  print('Closed form cost=',true_cost,'\\n')\n",
    "\n",
    "  print('predicted soln=',a[i,:],'sum of all execution=',torch.sum(a[i,:]).detach())\n",
    "  pred_cost=cost(a[i,:].detach().numpy())\n",
    "  print('predicted cost=',pred_cost,'\\n')\n",
    "  c_pred[i]=pred_cost\n",
    "  print('Percent Error in cost=',np.abs(100*(true_cost-pred_cost)/true_cost),'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIUWsQuCMJoI"
   },
   "source": [
    "Comparing the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "v2AdyYZLMHES",
    "outputId": "b299a6b2-a7cf-42e9-a2cf-5f39556e79d7"
   },
   "outputs": [],
   "source": [
    "# print(x1.shape)\n",
    "# name='E:/Robin research/ECMF_poster/N50.eps'\n",
    "# plt.figure()\n",
    "# plt.plot(x1,c_true,color='blue',label='cost_true',marker='1')\n",
    "# plt.plot(x1,c_pred,color='red',label='cost_predicted')\n",
    "# plt.plot(x1,c_num,color='green',label='cost_numeric')\n",
    "# plt.legend()\n",
    "# plt.savefig(name,format='eps')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDVg2A6yAt57"
   },
   "source": [
    "Comparing solution for diffeternt testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vOZyCiOfA2ej",
    "outputId": "43fe60aa-e0af-41d1-ca70-b0e9e8652ed9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n"
     ]
    }
   ],
   "source": [
    "p_soln=a.numpy()\n",
    "t_step=np.linspace(0,ite,num=ite+1)\n",
    "# name='/Users/shirinprovat/Desktop/Robin_Research/LOB_Linear/N_10_Linear.eps'\n",
    "def plotting(t):\n",
    "  #print('Total order size=',x1[t],np.sum(n_soln[t]),np.sum(p_soln[t]))\n",
    "  #print(n_soln[t],p_soln[t])\n",
    "  #plt.figure(figsize=(4,3))\n",
    "  plt.bar(t_step,t_soln[t],color='blue',width=0.3,label='Closed-Form')\n",
    "  plt.bar(t_step,p_soln[t],color='red',width=0.2,label='Predicted')\n",
    "  #plt.bar(t_step,n_soln[t],color='green',width=0.1,label='numeric')\n",
    "  plt.title('Total Order size X= %i' % (x1[t]))\n",
    "  plt.xlabel('Time steps')\n",
    "  plt.ylabel('Optimal orders')\n",
    "  plt.legend()\n",
    "\n",
    "  #plt.savefig('f.eps', format='eps')\n",
    "#   if(t==0):\n",
    "#     plt.savefig(name,format='eps')      \n",
    "  plt.show()\n",
    "for i in range(0,M1,3):\n",
    "  plotting(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'model_N10_T1_K1_rho5_neo20.pth') \n",
    "#model_coarse = torch.load('model_N10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# cost_numpy_list = [tensor.detach().item() for tensor in cost_ar]\n",
    "# my_dic = {'Num_sample':M,'Time_step':ite,'T':T,'kappa':kappa,'Rho':rho,'Total_balance':X0,\n",
    "#         'Num_neoron':neuron_model_psi,'Training_time':total_time,'epoch':max_epoch,\n",
    "#           'accuracy':0.005*1/100,'Training_cost':cost_numpy_list}\n",
    "\n",
    "# file_path=  'N10_T1_rho5_linear_dic.json'\n",
    "# with open(file_path,'w') as file:\n",
    "#     json.dump(my_dic,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDxwTUz0cM7i"
   },
   "source": [
    "Comparing solution at different time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "fhTjyEOhcTDi",
    "outputId": "f7434824-b622-4684-cba5-de03d91e7a07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "/var/folders/9f/dlwft6dn7hxg65r7xqyxvk6r0000gn/T/ipykernel_22636/2983102215.py:6: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(4,3))\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n"
     ]
    }
   ],
   "source": [
    "#p_soln=a.numpy()\n",
    "t_step=np.linspace(0,ite,num=ite+1)\n",
    "X=R_test.squeeze(1).numpy()\n",
    "def plotting_time(t):\n",
    "  #print(t_soln[t],p_soln[t])\n",
    "  plt.figure(figsize=(4,3))\n",
    "  plt.plot(X,t_soln[:,0],color='blue',label='true')\n",
    "  plt.plot(X,p_soln[:,0],color='red',label='pred')\n",
    "  plt.plot(X,n_soln[:,0],color='green',label='numeric')\n",
    "  plt.title('At time= %d' % (t_step[t]))\n",
    "  plt.xlabel('Total Order size')\n",
    "  plt.ylabel('Optimal orders')\n",
    "  plt.legend()\n",
    "  plt.show\n",
    "for i in range(0,t_step.shape[0],5):\n",
    "  plotting_time(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "freyX0vxj9Gi"
   },
   "source": [
    "Absolute sum of the difference between true solution, predicted solution and true soln, numeric soln at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "qKbuJp7tkOCY",
    "outputId": "7ae3d0aa-ccd8-442d-a735-0ac3915f0093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500.0      221.41187673622665\n",
      "9611.111328124998      230.0424365977047\n",
      "9722.22265625      240.5576000704491\n",
      "9833.3330078125      252.05621073784056\n",
      "9944.444335937496      263.8710108440346\n",
      "10055.555664062498      275.9676000520761\n",
      "10166.666992187502      288.0836555436982\n",
      "10277.77734375      300.2795533844354\n",
      "10388.888671874996      312.68681859704753\n",
      "10499.999999999996      325.2235683815835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9f/dlwft6dn7hxg65r7xqyxvk6r0000gn/T/ipykernel_22636/1059018647.py:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(4,2))\n",
      "Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x326c1e5d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_error=np.zeros(M1)\n",
    "sq_error_num=np.zeros(M1)\n",
    "\n",
    "for i in range(M1):\n",
    "  sq_error[i]=np.sum(np.abs(t_soln[i]-p_soln[i]))\n",
    "  sq_error_num[i]=np.sum(np.abs(t_soln[i]-n_soln[i]))\n",
    "  print(np.sum(t_soln[i]),'    ',sq_error[i])\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(X,sq_error,color='blue',label='pred')\n",
    "#plt.plot(X,sq_error_num,color='green',label='numeric')\n",
    "plt.title('Error with sample size= %d' % (M1))\n",
    "plt.xlabel('Total Order size')\n",
    "plt.ylabel('Sum of execution error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQzIyZHqqm5t"
   },
   "source": [
    "Additional rough test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-HLzw6CgLjT"
   },
   "outputs": [],
   "source": [
    "# from torch.nn.modules.pooling import MaxPool1d\n",
    "# M1=100\n",
    "# t_test=torch.zeros([M1,1])\n",
    "# D_test=torch.zeros([M1,1])\n",
    "# #D_test=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "# R_test=torch.linspace(50,100,100).unsqueeze(1)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "# x_test=torch.cat((t_test,D_test,R_test),dim=1)\n",
    "# #print('Input=',x_test,'\\n')\n",
    "# soln=[]\n",
    "# x_update = x_test\n",
    "# #print(x_update)\n",
    "# for i in range(ite+1):\n",
    "#     #print(x_update)\n",
    "#     soln_pred=model(x_update)\n",
    "#     #print(soln_pred)\n",
    "#     x_udpate=update(x_update,soln_pred.squeeze(1))\n",
    "#     #print(x_update)\n",
    "#     soln.append(soln_pred)\n",
    "# strategy = torch.cat(soln,dim=1)\n",
    "# print(strategy)\n",
    "# # print('predicted soln=',strategy,'sum of all execution=',torch.sum(strategy,dim=1),'\\n')\n",
    "# a=[]\n",
    "# b=[]\n",
    "# c=[]\n",
    "# for x in R_test:\n",
    "#     a.append(x.numpy()[0])\n",
    "#     y=closed_form(x.numpy()[0],ite+1)\n",
    "#     #print(y)\n",
    "#     b.append(y[0][0])\n",
    "#     c.append(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model= torch.load('model_N10.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.modules.pooling #model= torch.load('model_N10.pth')import MaxPool1d\n",
    "# M1=20\n",
    "# t_test=torch.zeros([M1,1])\n",
    "# D_test=torch.zeros([M1,1])\n",
    "# #D_test=torch.FloatTensor(M,1).uniform_(0.1,0.5)   #Price impact D_t\n",
    "# #R_test=torch.FloatTensor(M1,1).uniform_(50,100)   #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "# R_test=torch.linspace(X0*0.95, X0*1.05, steps=M1).unsqueeze(1)\n",
    "# x_test=torch.cat((t_test,D_test,R_test),dim=1)\n",
    "# #print('Input=',x_test,'\\n')\n",
    "# a=torch.zeros(M1,ite+1)\n",
    "# #print(a.shape)\n",
    "# for i in range(ite+1):\n",
    "#   if(i!=ite):\n",
    "#     #print(x_test)\n",
    "#     soln_pred=model(x_test).squeeze(1).detach()\n",
    "#     a[:,i]=soln_pred\n",
    "#     x_test=update(x_test,soln_pred)\n",
    "#     #print(x_test,'\\n')\n",
    "#   else:\n",
    "#     a[:,i]=R_test.squeeze(1)-torch.sum(a,dim=1)\n",
    "\n",
    "# x1=R_test.squeeze().numpy()\n",
    "# c_true=np.zeros(M1)\n",
    "# c_pred=np.zeros(M1)\n",
    "# c_num=np.zeros(M1)\n",
    "# n_soln=np.zeros((M1,ite+1))\n",
    "# t_soln=np.zeros((M1,ite+1))\n",
    "\n",
    "# for i in range(M1):\n",
    "#   print('size of total order=',x1[i])\n",
    "\n",
    "#   t_soln[i,:]=closed_form(x1[i])\n",
    "#   print('closed form soln=',t_soln[i,:],'sum of all execution=',np.sum(t_soln[i,:]))\n",
    "#   true_cost=cost(t_soln[i,:])\n",
    "#   c_true[i]=true_cost\n",
    "#   print('Closed form cost=',true_cost,'\\n')\n",
    "\n",
    "#   print('predicted soln=',a[i,:],'sum of all execution=',torch.sum(a[i,:]).detach())\n",
    "#   pred_cost=cost(a[i,:].detach().numpy())\n",
    "#   print('predicted cost=',pred_cost,'\\n')\n",
    "#   c_pred[i]=pred_cost\n",
    "#   print('Percent Error in cost=',np.abs(100*(true_cost-pred_cost)/true_cost),'%\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
